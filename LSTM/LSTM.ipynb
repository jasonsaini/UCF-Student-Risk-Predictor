{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b52ad8a-4146-4c25-86b8-554f2d253d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f856e724-3b47-4206-91c8-db0e793a53ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install keras\n",
    "!pip install --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784910c9-795a-43a0-b7bd-18f26a870b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235d230d-1ddd-4be9-987e-0c9b2396e3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = [ '../gradebook_data/1.csv' , '../gradebook_data/2.csv', '../gradebook_data/3.csv' , '../gradebook_data/4.csv' ]\n",
    "gradebooks = [pd.read_csv(file) for file in file_paths]\n",
    "gradebook_previews = [df.head() for df in gradebooks]\n",
    "gradebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ec8d0c-1440-468a-aa9e-f96112c8a722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the preprocessing steps to all datasets\n",
    "cleaned_gradebooks = []\n",
    "\n",
    "for df in gradebooks:\n",
    "    # Dropping rows and columns that are not relevant or are placeholders\n",
    "    df_cleaned = df.drop(index=[0, 1])  # Drop the first two rows which are placeholders\n",
    "    df_cleaned = df_cleaned.drop(columns=[\"ID\", \"SIS User ID\", \"SIS Login ID\", \"Root Account\", \"Section\"])  # Drop identifier columns\n",
    "\n",
    "    # Handling missing values - Assuming that missing values in grades can be treated as zeros\n",
    "    df_cleaned = df_cleaned.fillna(0)\n",
    "\n",
    "    # Convert grades to numeric where possible\n",
    "    for col in df_cleaned.columns[1:]:  # Skipping the first column which is the student name\n",
    "        df_cleaned[col] = pd.to_numeric(df_cleaned[col], errors='coerce').fillna(0)\n",
    "    \n",
    "    cleaned_gradebooks.append(df_cleaned)\n",
    "\n",
    "# Displaying the first few rows of each cleaned dataset\n",
    "cleaned_gradebook_previews = [df.head() for df in cleaned_gradebooks]\n",
    "cleaned_gradebook_previews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bac8a9-32b1-4f78-8d2e-6bde6db2af99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the cleaned datasets\n",
    "concatenated_df = pd.concat(cleaned_gradebooks, ignore_index=True)\n",
    "\n",
    "# Display the shape of the concatenated dataset and the first few rows\n",
    "concatenated_df_shape = concatenated_df.shape\n",
    "concatenated_df_head = concatenated_df.head()\n",
    "\n",
    "concatenated_df_shape, concatenated_df_head\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfc5885-1841-4308-81c1-555df7cfe6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifying the column for the final score (assuming the last few columns are summary columns)\n",
    "final_score_column = 'Final Score' if 'Final Score' in concatenated_df.columns else concatenated_df.columns[-3]\n",
    "concatenated_df['At_Risk'] = concatenated_df[final_score_column] < 60  # 'At_Risk' is True if Final Score is less than 60\n",
    "concatenated_df = concatenated_df.copy()\n",
    "# Preparing data for LSTM\n",
    "# We'll drop columns that are not relevant for LSTM (like final scores, grades, and student identifiers)\n",
    "lstm_features = concatenated_df.drop(columns=[final_score_column, 'Current Score', 'Unposted Current Score', \n",
    "                                              'Unposted Final Score', 'Current Grade', 'Unposted Current Grade', \n",
    "                                              'Final Grade', 'Unposted Final Grade', 'Student'])\n",
    "\n",
    "# For LSTM, we need to ensure all sequences (rows) are of the same length\n",
    "# We'll pad shorter sequences with zeros\n",
    "max_sequence_length = lstm_features.shape[1]\n",
    "lstm_features = lstm_features.to_numpy()\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(lstm_features, concatenated_df['At_Risk'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Displaying the shapes of the training and testing sets\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f11447f-02fc-4178-addf-cf5e08e60ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(50, return_sequences=True, input_shape=(X_train.shape[1], 1)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(50, return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(25))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51f957b-92c8-46ac-9d5e-342c7560ebb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_reshaped = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test_reshaped = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "X_test_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3412557c-b1ad-4b9f-9fed-4b8db75b6393",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_reshaped = X_test_reshaped.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcd71eb-6261-4d61-b5b4-ed5a0ecb67e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions\n",
    "predictions = model.predict(X_test_reshaped)\n",
    "threshold = 0.3  # Example threshold, adjust as needed\n",
    "predicted_labels = (predictions > threshold).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90568de-f048-4377-b834-4f756131071a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c22db4-d7c0-43fc-be2a-955a030d07f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94e76fd-49fa-42a3-8a60-479d25340915",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d84a30-421f-4b43-a10d-8c18bdc90dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert y_test to binary if it's not already\n",
    "y_test_binary = y_test.astype(int)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test_binary, predicted_labels)\n",
    "precision = precision_score(y_test_binary, predicted_labels)\n",
    "recall = recall_score(y_test_binary, predicted_labels)\n",
    "f1 = f1_score(y_test_binary, predicted_labels)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test_binary, predicted_labels)\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61bc457-58d4-4cd0-bde5-3373a8d10066",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
